[{"path":"https://multidplyr.tidyverse.org/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 multidplyr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://multidplyr.tidyverse.org/articles/multidplyr.html","id":"creating-a-cluster","dir":"Articles","previous_headings":"","what":"Creating a cluster","title":"An introduction to multidplyr","text":"start using multidplyr must create cluster. used two cores ’s maximum permitted CRAN, suggest use . best performance, recommend using 1 2 fewer total number cores computer, can detect parallel::detectCores() (leaving least 1 core free means still able use computer tasks computation running). (examples, ’ll also see use default_cluster(); designed specifically constraints R CMD check, don’t recommend using code.) cluster consists multiple R processes created callr. multiple processes running time, operating system take care spreading work across multiple cores.","code":"cluster <- new_cluster(2) cluster #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/articles/multidplyr.html","id":"add-data","dir":"Articles","previous_headings":"","what":"Add data","title":"An introduction to multidplyr","text":"two ways get data workers cluster: partition() data frame already loaded interactive process. Load different subset data worker.","code":""},{"path":"https://multidplyr.tidyverse.org/articles/multidplyr.html","id":"partition","dir":"Articles","previous_headings":"Add data","what":"partition()","title":"An introduction to multidplyr","text":"partition() useful single -memory data frame. example, take nycflights13::flights. dataset contains information ~300,000 flights departing New York City 2013. group destination, partition : partition() splits flights1 roughly equal subsets worker, ensuring rows group transfered worker. result party_df, partitioned data frame.","code":"flights1 <- flights %>% group_by(dest) %>% partition(cluster) flights1 #> Source: party_df [336,776 x 19] #> Groups: dest #> Shards: 2 [166,251--170,525 rows] #>  #>    year month   day dep_ti… sched_… dep_de… arr_ti… sched_… arr_de… #>   <int> <int> <int>   <int>   <int>   <dbl>   <int>   <int>   <dbl> #> 1  2013     1     1     557     600      -3     709     723     -14 #> 2  2013     1     1     557     600      -3     838     846      -8 #> 3  2013     1     1     558     600      -2     849     851      -2 #> 4  2013     1     1     558     600      -2     853     856      -3 #> 5  2013     1     1     559     559       0     702     706      -4 #> 6  2013     1     1     559     600      -1     854     902      -8 #> # … with 336,770 more rows, and 10 more variables: carrier <chr>, #> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, #> #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, #> #   time_hour <dttm>"},{"path":"https://multidplyr.tidyverse.org/articles/multidplyr.html","id":"direct-loading","dir":"Articles","previous_headings":"Add data","what":"Direct loading","title":"An introduction to multidplyr","text":"partition() simple call, ’s relatively expensive copies lot data processes. alternative strategy worker load data (files) needs directly. show might work, ’ll first split flights month save csv files: Now find files directory, divide worker gets (approximately) number pieces: read files worker use party_df() create partitioned dataframe:","code":"path <- tempfile() dir.create(path)  flights %>%    group_by(month) %>%    group_walk(~ vroom::vroom_write(.x, sprintf(\"%s/month-%02i.csv\", path, .y$month))) files <- dir(path, full.names = TRUE) cluster_assign_partition(cluster, files = files) cluster_send(cluster, flights2 <- vroom::vroom(files))  flights2 <- party_df(cluster, \"flights2\") flights2 #> Source: party_df [336,776 x 18] #> Shards: 2 [166,158--170,618 rows] #>  #>    year   day dep_ti… sched_… dep_de… arr_ti… sched_… arr_de… carrier #>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   #> 1  2013     1     517     515       2     830     819      11 UA      #> 2  2013     1     533     529       4     850     830      20 UA      #> 3  2013     1     542     540       2     923     850      33 AA      #> 4  2013     1     544     545      -1    1004    1022     -18 B6      #> 5  2013     1     554     600      -6     812     837     -25 DL      #> 6  2013     1     554     558      -4     740     728      12 UA      #> # … with 336,770 more rows, and 9 more variables: flight <dbl>, #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, #> #   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>"},{"path":"https://multidplyr.tidyverse.org/articles/multidplyr.html","id":"dplyr-verbs","dir":"Articles","previous_headings":"","what":"dplyr verbs","title":"An introduction to multidplyr","text":"partitioned data frame, can operate usual dplyr verbs. bring data back interactive process, use collect(): size data simple transformation, using local cluster actually makes performance much worse! ’s overhead associated sending data worker retrieving results end. basic dplyr verbs, multidplyr unlikely give significant speed ups unless 10s 100s millions data points (scenario first try dtplyr, uses data.table). multipldyr might help, however, ’re complex things. Let’s see plays fitting moderately complex model. ’ll start selecting subset flights least 50 occurrences, ’ll compute day year date: leaves us ~332,000 observations. Let’s partition smaller dataset: Let’s fit smoothed generalised additive model destination, estimating delays vary course year within day. Note need use cluster_library() load mgcv package every node. takes around 3s: Compared around 5s locally: cost transmitting messages nodes roughly constant, longer task ’re parallelising, closer ’ll get linear speed .","code":"flights1 %>%    summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %>%    collect() #> # A tibble: 105 × 2 #>    dest  dep_delay #>    <chr>     <dbl> #>  1 ABQ       13.7  #>  2 ALB       23.6  #>  3 AUS       13.0  #>  4 AVL        8.19 #>  5 BDL       17.7  #>  6 BGR       19.5  #>  7 BHM       29.7  #>  8 BNA       16.0  #>  9 BOS        8.73 #> 10 BZN       11.5  #> # … with 95 more rows by_dest <- flights %>% group_by(dest)  # Local computation system.time(by_dest %>% summarise(mean(dep_delay, na.rm = TRUE))) #>    user  system elapsed  #>   0.014   0.000   0.015  # Remote: partitioning system.time(flights2 <- flights %>% partition(cluster)) #>    user  system elapsed  #>   0.481   0.075   0.618 # Remote: computation system.time(flights3 <- flights2 %>% summarise(mean(dep_delay, na.rm = TRUE))) #>    user  system elapsed  #>   0.008   0.000   0.045 # Remote: retrieve results system.time(flights3 %>% collect()) #>    user  system elapsed  #>   0.008   0.000   0.059 daily_flights <- flights %>%   count(dest) %>%   filter(n >= 365)  common_dest <- flights %>%    semi_join(daily_flights, by = \"dest\") %>%    mutate(yday = lubridate::yday(ISOdate(year, month, day))) %>%    group_by(dest)  nrow(common_dest) #> [1] 332942 by_dest <- common_dest %>% partition(cluster) by_dest #> Source: party_df [332,942 x 20] #> Groups: dest #> Shards: 2 [164,539--168,403 rows] #>  #>    year month   day dep_ti… sched_… dep_de… arr_ti… sched_… arr_de… #>   <int> <int> <int>   <int>   <int>   <dbl>   <int>   <int>   <dbl> #> 1  2013     1     1     517     515       2     830     819      11 #> 2  2013     1     1     533     529       4     850     830      20 #> 3  2013     1     1     542     540       2     923     850      33 #> 4  2013     1     1     554     558      -4     740     728      12 #> 5  2013     1     1     555     600      -5     913     854      19 #> 6  2013     1     1     558     600      -2     753     745       8 #> # … with 332,936 more rows, and 11 more variables: carrier <chr>, #> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, #> #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, #> #   time_hour <dttm>, yday <dbl> cluster_library(cluster, \"mgcv\") system.time({   models <- by_dest %>%      do(mod = gam(dep_delay ~ s(yday) + s(dep_time), data = .)) }) #>    user  system elapsed  #>   0.010   0.003   3.045 system.time({   models <- common_dest %>%      group_by(dest) %>%      do(mod = gam(dep_delay ~ s(yday) + s(dep_time), data = .)) }) #>    user  system elapsed  #>   4.949   0.055   5.005"},{"path":"https://multidplyr.tidyverse.org/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hadley Wickham. Author, maintainer. . Copyright holder, funder.","code":""},{"path":"https://multidplyr.tidyverse.org/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wickham H (2022). multidplyr: Multi-Process 'dplyr' Backend. https://multidplyr.tidyverse.org, https://github.com/tidyverse/multidplyr.","code":"@Manual{,   title = {multidplyr: A Multi-Process 'dplyr' Backend},   author = {Hadley Wickham},   year = {2022},   note = {https://multidplyr.tidyverse.org, https://github.com/tidyverse/multidplyr}, }"},{"path":[]},{"path":"https://multidplyr.tidyverse.org/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Multi-Process dplyr Backend","text":"multidplyr backend dplyr partitions data frame across multiple cores. tell multidplyr split data partition() data stays node explicitly retrieve collect(). minimises amount time spent moving data around, maximises parallel performance. idea inspired partools Norm Matloff distributedR Vertica Analytics team. Due overhead associated communicating nodes, won’t see much performance improvement simple operations less ~10 million observations, may want instead try dtplyr, uses data.table. multidplyr’s strength found parallelising calls slower complex functions. (Note unlike packages tidyverse, multidplyr requires R 3.5 greater. hope relax requirement future.)","code":""},{"path":"https://multidplyr.tidyverse.org/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Multi-Process dplyr Backend","text":"can install released version multidplyr CRAN : development version GitHub :","code":"install.packages(\"multidplyr\") # install.packages(\"devtools\") devtools::install_github(\"tidyverse/multidplyr\")"},{"path":"https://multidplyr.tidyverse.org/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"A Multi-Process dplyr Backend","text":"use multidplyr, first create cluster desired number workers. one workers separate R process, operating system spread execution across multiple cores: two primary ways use multidplyr. first, efficient, way read different files worker: Alternatively, already data loaded main session, can use partition() automatically spread across workers. calling partition(), ’s good idea call group_by() ensure observations belonging group end worker. Now can work like regular data frame, computations spread across multiple cores. ’ve finished computation, use collect() bring data back host session: Note overhead associated copying data worker nodes back host node (vice versa), ’re best using multidplyr complex operations. See vignette(\"multidplyr\") details.","code":"library(multidplyr)  cluster <- new_cluster(4) cluster_library(cluster, \"dplyr\") #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union # Create a filename vector containing different values on each worker cluster_assign_each(cluster, filename = c(\"a.csv\", \"b.csv\", \"c.csv\", \"d.csv\"))  # Use vroom to quickly load the csvs cluster_send(cluster, my_data <- vroom::vroom(filename))  # Create a party_df using the my_data variable on each worker my_data <- party_df(cluster, \"my_data\") library(nycflights13)  flight_dest <- flights %>% group_by(dest) %>% partition(cluster) flight_dest #> Source: party_df [336,776 x 19] #> Groups: dest #> Shards: 4 [81,594--86,548 rows] #>  #>    year month   day dep_ti… sched_… dep_de… arr_ti… sched_… arr_de… carrier #>   <int> <int> <int>   <int>   <int>   <dbl>   <int>   <int>   <dbl> <chr>   #> 1  2013     1     1     544     545      -1    1004    1022     -18 B6      #> 2  2013     1     1     558     600      -2     923     937     -14 UA      #> 3  2013     1     1     559     600      -1     854     902      -8 UA      #> 4  2013     1     1     602     610      -8     812     820      -8 DL      #> 5  2013     1     1     602     605      -3     821     805      16 MQ      #> 6  2013     1     1     611     600      11     945     931      14 UA      #> # … with 336,770 more rows, and 9 more variables: flight <int>, tailnum <chr>, #> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, #> #   minute <dbl>, time_hour <dttm> flight_dest %>%    summarise(delay = mean(dep_delay, na.rm = TRUE), n = n()) %>%    collect() #> # A tibble: 105 × 3 #>    dest  delay     n #>    <chr> <dbl> <int> #>  1 ABQ    13.7   254 #>  2 AUS    13.0  2439 #>  3 BQN    12.4   896 #>  4 BTV    13.6  2589 #>  5 BUF    13.4  4681 #>  6 CLE    13.4  4573 #>  7 CMH    12.2  3524 #>  8 DEN    15.2  7266 #>  9 DSM    26.2   569 #> 10 DTW    11.8  9384 #> # … with 95 more rows"},{"path":"https://multidplyr.tidyverse.org/reference/cluster_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a function on each node of a cluster — cluster_call","title":"Call a function on each node of a cluster — cluster_call","text":"`cluster_call()` executes code worker returns results; `cluster_send()` executes code ignoring result. Jobs submitted workers parallel, wait complete.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a function on each node of a cluster — cluster_call","text":"","code":"cluster_call(cluster, code, simplify = FALSE, ptype = NULL)  cluster_send(cluster, code)"},{"path":"https://multidplyr.tidyverse.org/reference/cluster_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a function on each node of a cluster — cluster_call","text":"cluster cluster. code expression execute worker. simplify results simplified list?   * `TRUE`: simplify die trying.   * `NA`: simplify possible.   * `FALSE`: never try simplify, always leaving list. `code` must return vector length one order simplification   succeed. ptype `simplify` `TRUE`, use `ptype` enforce desired output type.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a function on each node of a cluster — cluster_call","text":"list results one element worker `cluster`.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_call.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a function on each node of a cluster — cluster_call","text":"","code":"cl <- default_cluster() #> Initialising default cluster of size 2  # Run code on each cluster and retrieve results cluster_call(cl, Sys.getpid()) #> [[1]] #> [1] 11581 #>  #> [[2]] #> [1] 11587 #>  cluster_call(cl, runif(1)) #> [[1]] #> [1] 0.308746 #>  #> [[2]] #> [1] 0.6580173 #>   # use ptype to simplify cluster_call(cl, runif(1), simplify = TRUE) #> [1] 0.6343322 0.9666855  # use cluster_send() to ignore results cluster_send(cl, x <- runif(1)) cluster_call(cl, x, simplify = TRUE) #> [1] 0.2813766 0.1251119"},{"path":"https://multidplyr.tidyverse.org/reference/cluster_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster utitility functions — cluster_utils","title":"Cluster utitility functions — cluster_utils","text":"functions provide useful helpers performaning common operations. `cluster_assign()` assigns value worker; `cluster_assign_each()` assigns different values worker; `cluster_assign_partition()` partitions vectors worker gets (approximately) number pieces.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_utils.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster utitility functions — cluster_utils","text":"","code":"cluster_assign(.cluster, ...)  cluster_assign_each(.cluster, ...)  cluster_assign_partition(.cluster, ...)  cluster_copy(cluster, names, env = caller_env())  cluster_rm(cluster, names)  cluster_library(cluster, packages)"},{"path":"https://multidplyr.tidyverse.org/reference/cluster_utils.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster utitility functions — cluster_utils","text":"... Name-value pairs cluster, .cluster Cluster work names Name variables copy. env Environment look varibles copy. packages Character vector packages load","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_utils.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster utitility functions — cluster_utils","text":"Functions modify worker environment invisibly return   `cluster` calls can piped together. functions return   lists one element worker.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/cluster_utils.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster utitility functions — cluster_utils","text":"","code":"cl <- default_cluster() cluster_assign(cl, a = runif(1)) cluster_call(cl, a) #> [[1]] #> [1] 0.8049974 #>  #> [[2]] #> [1] 0.8049974 #>   # Assign different values on each cluster cluster_assign_each(cl, b = c(1, 10)) cluster_call(cl, b) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 10 #>   # Partition a vector so that each worker gets approximately the # same amount of it cluster_assign_partition(cl, c = 1:11) cluster_call(cl, c) #> [[1]] #> [1] 1 2 3 4 5 6 #>  #> [[2]] #> [1]  7  8  9 10 11 #>   # If you want different to compute different values on each # worker, use `cluster_call()` directly: cluster_call(cl, d <- runif(1)) #> [[1]] #> [1] 0.01855738 #>  #> [[2]] #> [1] 0.6772187 #>  cluster_call(cl, d) #> [[1]] #> [1] 0.01855738 #>  #> [[2]] #> [1] 0.6772187 #>   # cluster_copy() is a useful shortcut e <- 10 cluster_copy(cl, \"e\")  cluster_call(cl, ls()) #> [[1]] #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"x\" #>  #> [[2]] #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"x\" #>  cluster_rm(cl, letters[1:5]) cluster_call(cl, ls()) #> [[1]] #> [1] \"x\" #>  #> [[2]] #> [1] \"x\" #>   # Use cluster_library() to load packages cluster_call(cl, search()) #> [[1]] #>  [1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\"  #>  [4] \"package:grDevices\" \"package:utils\"     \"package:datasets\"  #>  [7] \"package:methods\"   \"Autoloads\"         \"tools:callr\"       #> [10] \"package:base\"      #>  #> [[2]] #>  [1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\"  #>  [4] \"package:grDevices\" \"package:utils\"     \"package:datasets\"  #>  [7] \"package:methods\"   \"Autoloads\"         \"tools:callr\"       #> [10] \"package:base\"      #>  cluster_library(cl, \"magrittr\") cluster_call(cl, search()) #> [[1]] #>  [1] \".GlobalEnv\"        \"package:magrittr\"  \"package:stats\"     #>  [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"     #>  [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"         #> [10] \"tools:callr\"       \"package:base\"      #>  #> [[2]] #>  [1] \".GlobalEnv\"        \"package:magrittr\"  \"package:stats\"     #>  [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"     #>  [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"         #> [10] \"tools:callr\"       \"package:base\"      #>"},{"path":"https://multidplyr.tidyverse.org/reference/default_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Default cluster — default_cluster","title":"Default cluster — default_cluster","text":"Setting cluster relatively expensive, best use single cluster throughout session. function lazily creates 2-worker cluster use examples test.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/default_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default cluster — default_cluster","text":"","code":"default_cluster(n = 2)"},{"path":"https://multidplyr.tidyverse.org/reference/default_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default cluster — default_cluster","text":"n Number workers use; defaults 2 maximum allowed CRAN.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/default_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default cluster — default_cluster","text":"cached cluster workers.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/default_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default cluster — default_cluster","text":"","code":"default_cluster() #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/reference/multidplyr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","title":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","text":"Partition data frame across multiple worker processes provide simple multicore parallelism.","code":""},{"path":[]},{"path":"https://multidplyr.tidyverse.org/reference/multidplyr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","text":"Maintainer: Hadley Wickham hadley@rstudio.com contributors: RStudio [copyright holder, funder]","code":""},{"path":"https://multidplyr.tidyverse.org/reference/new_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new cluster with sensible defaults. — new_cluster","title":"Create a new cluster with sensible defaults. — new_cluster","text":"Clusters created function automatically clean .","code":""},{"path":"https://multidplyr.tidyverse.org/reference/new_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new cluster with sensible defaults. — new_cluster","text":"","code":"new_cluster(n)"},{"path":"https://multidplyr.tidyverse.org/reference/new_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new cluster with sensible defaults. — new_cluster","text":"n Number workers create. Avoid setting higher number cores computer degrade performance.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/new_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new cluster with sensible defaults. — new_cluster","text":"`multidplyr_cluster` object.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/new_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new cluster with sensible defaults. — new_cluster","text":"","code":"cluster <- new_cluster(2) cluster #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/reference/partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition data across workers in a cluster — partition","title":"Partition data across workers in a cluster — partition","text":"Partitioning ensures observations group end worker. try keep observations worker balanced, `partition()` uses greedy algorithm iteratively assigns group worker currently fewest rows.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition data across workers in a cluster — partition","text":"","code":"partition(data, cluster)"},{"path":"https://multidplyr.tidyverse.org/reference/partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition data across workers in a cluster — partition","text":"data Dataset partition, typically grouped. grouped, observations group assigned cluster. cluster Cluster use.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition data across workers in a cluster — partition","text":"[party_df].","code":""},{"path":"https://multidplyr.tidyverse.org/reference/partition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition data across workers in a cluster — partition","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union cl <- default_cluster() cluster_library(cl, \"dplyr\")  mtcars2 <- partition(mtcars, cl) mtcars2 %>% mutate(cyl2 = 2 * cyl) #> Source: party_df [32 x 12] #> Shards: 2 [16--16 rows] #>  #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb  cyl2 #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4    12 #> 2  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1     8 #> 3  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2    16 #> 4  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4    16 #> 5  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2     8 #> 6  17.8     6  168.   123  3.92  3.44  18.9     1     0     4     4    12 #> # … with 26 more rows mtcars2 %>% filter(vs == 1) #> Source: party_df [14 x 11] #> Shards: 2 [5--9 rows] #>  #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  22.8     4 108      93  3.85  2.32  18.6     1     1     4     1 #> 2  22.8     4 141.     95  3.92  3.15  22.9     1     0     4     2 #> 3  17.8     6 168.    123  3.92  3.44  18.9     1     0     4     4 #> 4  30.4     4  75.7    52  4.93  1.62  18.5     1     1     4     2 #> 5  21.5     4 120.     97  3.7   2.46  20.0     1     0     3     1 #> 6  21.4     6 258     110  3.08  3.22  19.4     1     0     3     1 #> # … with 8 more rows mtcars2 %>% group_by(cyl) %>% summarise(n()) #> Source: party_df [6 x 2] #> Shards: 2 [3--3 rows] #>  #>     cyl `n()` #>   <dbl> <int> #> 1     4     5 #> 2     6     2 #> 3     8     9 #> 4     4     6 #> 5     6     5 #> 6     8     5 mtcars2 %>% select(-cyl) #> Source: party_df [32 x 10] #> Shards: 2 [16--16 rows] #>  #>     mpg  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21    160    110  3.9   2.62  16.5     0     1     4     4 #> 2  22.8  108     93  3.85  2.32  18.6     1     1     4     1 #> 3  18.7  360    175  3.15  3.44  17.0     0     0     3     2 #> 4  14.3  360    245  3.21  3.57  15.8     0     0     3     4 #> 5  22.8  141.    95  3.92  3.15  22.9     1     0     4     2 #> 6  17.8  168.   123  3.92  3.44  18.9     1     0     4     4 #> # … with 26 more rows"},{"path":"https://multidplyr.tidyverse.org/reference/party_df.html","id":null,"dir":"Reference","previous_headings":"","what":"A `party_df` partitioned data frame — party_df","title":"A `party_df` partitioned data frame — party_df","text":"S3 class represents data frame partitioned across workers cluster. can use constructor already spread data frames spread across cluster. , start [partition()] instead.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/party_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A `party_df` partitioned data frame — party_df","text":"","code":"party_df(cluster, name, auto_rm = FALSE)"},{"path":"https://multidplyr.tidyverse.org/reference/party_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A `party_df` partitioned data frame — party_df","text":"cluster cluster name Name data frame variable. Must exist every worker, data frame, names. auto_rm `TRUE`, automatically `rm()` data frame workers object created.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/party_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A `party_df` partitioned data frame — party_df","text":"S3 object class `multidplyr_party_df`.","code":""},{"path":"https://multidplyr.tidyverse.org/reference/party_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A `party_df` partitioned data frame — party_df","text":"","code":"# If a real example, you might spread file names across the clusters # and read in using data.table::fread()/vroom::vroom()/qs::qread(). cl <- default_cluster() cluster_send(cl[1], n <- 10) cluster_send(cl[2], n <- 15) cluster_send(cl, df <- data.frame(x = runif(n)))  df <- party_df(cl, \"df\") df #> Source: party_df [25 x 1] #> Shards: 2 [10--15 rows] #>  #>        x #>    <dbl> #> 1 0.0611 #> 2 0.210  #> 3 0.167  #> 4 0.436  #> 5 0.844  #> 6 0.838  #> # … with 19 more rows"},{"path":"https://multidplyr.tidyverse.org/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. magrittr %>%","code":""},{"path":"https://multidplyr.tidyverse.org/news/index.html","id":"multidplyr-012","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.2","title":"multidplyr 0.1.2","text":"cluster_call() gains simplify argument - use request result simplified (#136).","code":""},{"path":"https://multidplyr.tidyverse.org/news/index.html","id":"multidplyr-011","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.1","title":"multidplyr 0.1.1","text":"CRAN release: 2021-12-01 Fixed problems identified part working dplyr 1.0.8.","code":""},{"path":"https://multidplyr.tidyverse.org/news/index.html","id":"multidplyr-010","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.0","title":"multidplyr 0.1.0","text":"CRAN release: 2021-02-08 Added NEWS.md file track changes package.","code":""}]
