[{"path":[]},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@posit.co. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 multidplyr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/articles/multidplyr.html","id":"creating-a-cluster","dir":"Articles","previous_headings":"","what":"Creating a cluster","title":"An introduction to multidplyr","text":"start using multidplyr must create cluster. used two cores ’s maximum permitted CRAN, suggest use . best performance, recommend using 1 2 fewer total number cores computer, can detect parallel::detectCores() (leaving least 1 core free means still able use computer tasks computation running). (examples, ’ll also see use default_cluster(); designed specifically constraints R CMD check, don’t recommend using code.) cluster consists multiple R processes created callr. multiple processes running time, operating system take care spreading work across multiple cores.","code":"cluster <- new_cluster(2) cluster #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/dev/articles/multidplyr.html","id":"add-data","dir":"Articles","previous_headings":"","what":"Add data","title":"An introduction to multidplyr","text":"two ways get data workers cluster: partition() data frame already loaded interactive process. Load different subset data worker.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/articles/multidplyr.html","id":"partition","dir":"Articles","previous_headings":"Add data","what":"partition()","title":"An introduction to multidplyr","text":"partition() useful single -memory data frame. example, take nycflights13::flights. dataset contains information ~300,000 flights departing New York City 2013. group destination, partition : partition() splits flights1 roughly equal subsets worker, ensuring rows group transfered worker. result party_df, partitioned data frame.","code":"flights1 <- flights %>% group_by(dest) %>% partition(cluster) flights1 #> Source: party_df [336,776 x 19] #> Groups: dest #> Shards: 2 [166,251--170,525 rows] #>  #> # A data frame: 336,776 × 19 #>    year month   day dep_time sched_dep_time dep_delay arr_time #>   <int> <int> <int>    <int>          <int>     <dbl>    <int> #> 1  2013     1     1      557            600        -3      709 #> 2  2013     1     1      557            600        -3      838 #> 3  2013     1     1      558            600        -2      849 #> 4  2013     1     1      558            600        -2      853 #> 5  2013     1     1      559            559         0      702 #> 6  2013     1     1      559            600        -1      854 #> # ℹ 336,770 more rows #> # ℹ 12 more variables: sched_arr_time <int>, arr_delay <dbl>, #> #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>, #> #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, #> #   time_hour <dttm>"},{"path":"https://multidplyr.tidyverse.org/dev/articles/multidplyr.html","id":"direct-loading","dir":"Articles","previous_headings":"Add data","what":"Direct loading","title":"An introduction to multidplyr","text":"partition() simple call, ’s relatively expensive copies lot data processes. alternative strategy worker load data (files) needs directly. show might work, ’ll first split flights month save csv files: Now find files directory, divide worker gets (approximately) number pieces: read files worker use party_df() create partitioned dataframe:","code":"path <- tempfile() dir.create(path)  flights %>%    group_by(month) %>%    group_walk(~ vroom::vroom_write(.x, sprintf(\"%s/month-%02i.csv\", path, .y$month))) files <- dir(path, full.names = TRUE) cluster_assign_partition(cluster, files = files) cluster_send(cluster, flights2 <- vroom::vroom(files))  flights2 <- party_df(cluster, \"flights2\") flights2 #> Source: party_df [336,776 x 18] #> Shards: 2 [166,158--170,618 rows] #>  #> # A data frame: 336,776 × 18 #>    year   day dep_time sched_dep_time dep_delay arr_time sched_arr_time #>   <dbl> <dbl>    <dbl>          <dbl>     <dbl>    <dbl>          <dbl> #> 1  2013     1      517            515         2      830            819 #> 2  2013     1      533            529         4      850            830 #> 3  2013     1      542            540         2      923            850 #> 4  2013     1      544            545        -1     1004           1022 #> 5  2013     1      554            600        -6      812            837 #> 6  2013     1      554            558        -4      740            728 #> # ℹ 336,770 more rows #> # ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <dbl>, #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, #> #   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>"},{"path":"https://multidplyr.tidyverse.org/dev/articles/multidplyr.html","id":"dplyr-verbs","dir":"Articles","previous_headings":"","what":"dplyr verbs","title":"An introduction to multidplyr","text":"partitioned data frame, can operate usual dplyr verbs. bring data back interactive process, use collect(): size data simple transformation, using local cluster actually makes performance much worse! ’s overhead associated sending data worker retrieving results end. basic dplyr verbs, multidplyr unlikely give significant speed ups unless 10s 100s millions data points (scenario first try dtplyr, uses data.table). multipldyr might help, however, ’re complex things. Let’s see plays fitting moderately complex model. ’ll start selecting subset flights least 50 occurrences, ’ll compute day year date: leaves us ~332,000 observations. Let’s partition smaller dataset: Let’s fit smoothed generalised additive model destination, estimating delays vary course year within day. Note need use cluster_library() load mgcv package every node. takes around 3s: Compared around 5s locally: cost transmitting messages nodes roughly constant, longer task ’re parallelising, closer ’ll get linear speed .","code":"flights1 %>%    summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %>%    collect() #> # A tibble: 105 × 2 #>    dest  dep_delay #>    <chr>     <dbl> #>  1 ABQ       13.7  #>  2 ALB       23.6  #>  3 AUS       13.0  #>  4 AVL        8.19 #>  5 BDL       17.7  #>  6 BGR       19.5  #>  7 BHM       29.7  #>  8 BNA       16.0  #>  9 BOS        8.73 #> 10 BZN       11.5  #> # ℹ 95 more rows by_dest <- flights %>% group_by(dest)  # Local computation system.time(by_dest %>% summarise(mean(dep_delay, na.rm = TRUE))) #>    user  system elapsed  #>    0.01    0.00    0.01  # Remote: partitioning system.time(flights2 <- flights %>% partition(cluster)) #>    user  system elapsed  #>   0.291   0.069   0.408 # Remote: computation system.time(flights3 <- flights2 %>% summarise(mean(dep_delay, na.rm = TRUE))) #>    user  system elapsed  #>   0.003   0.004   0.036 # Remote: retrieve results system.time(flights3 %>% collect()) #>    user  system elapsed  #>   0.007   0.000   0.049 daily_flights <- flights %>%   count(dest) %>%   filter(n >= 365)  common_dest <- flights %>%    semi_join(daily_flights, by = \"dest\") %>%    mutate(yday = lubridate::yday(ISOdate(year, month, day))) %>%    group_by(dest)  nrow(common_dest) #> [1] 332942 by_dest <- common_dest %>% partition(cluster) by_dest #> Source: party_df [332,942 x 20] #> Groups: dest #> Shards: 2 [164,539--168,403 rows] #>  #> # A data frame: 332,942 × 20 #>    year month   day dep_time sched_dep_time dep_delay arr_time #>   <int> <int> <int>    <int>          <int>     <dbl>    <int> #> 1  2013     1     1      517            515         2      830 #> 2  2013     1     1      533            529         4      850 #> 3  2013     1     1      542            540         2      923 #> 4  2013     1     1      554            558        -4      740 #> 5  2013     1     1      555            600        -5      913 #> 6  2013     1     1      558            600        -2      753 #> # ℹ 332,936 more rows #> # ℹ 13 more variables: sched_arr_time <int>, arr_delay <dbl>, #> #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>, #> #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, #> #   time_hour <dttm>, yday <dbl> cluster_library(cluster, \"mgcv\") system.time({   models <- by_dest %>%      do(mod = gam(dep_delay ~ s(yday) + s(dep_time), data = .)) }) #>    user  system elapsed  #>   0.008   0.000   3.613 system.time({   models <- common_dest %>%      group_by(dest) %>%      do(mod = gam(dep_delay ~ s(yday) + s(dep_time), data = .)) }) #>    user  system elapsed  #>   5.085   7.719   3.331"},{"path":"https://multidplyr.tidyverse.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hadley Wickham. Author, maintainer. . Copyright holder, funder.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wickham H (2024). multidplyr: Multi-Process 'dplyr' Backend. R package version 0.1.3.9000, https://github.com/tidyverse/multidplyr, https://multidplyr.tidyverse.org.","code":"@Manual{,   title = {multidplyr: A Multi-Process 'dplyr' Backend},   author = {Hadley Wickham},   year = {2024},   note = {R package version 0.1.3.9000,     https://github.com/tidyverse/multidplyr},   url = {https://multidplyr.tidyverse.org}, }"},{"path":[]},{"path":"https://multidplyr.tidyverse.org/dev/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Multi-Process dplyr Backend","text":"multidplyr backend dplyr partitions data frame across multiple cores. tell multidplyr split data partition() data stays node explicitly retrieve collect(). minimises amount time spent moving data around, maximises parallel performance. idea inspired partools Norm Matloff distributedR Vertica Analytics team. Due overhead associated communicating nodes, won’t see much performance improvement simple operations less ~10 million observations, may want instead try dtplyr, uses data.table. multidplyr’s strength found parallelising calls slower complex functions. (Note unlike packages tidyverse, multidplyr requires R 3.5 greater. hope relax requirement future.)","code":""},{"path":"https://multidplyr.tidyverse.org/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Multi-Process dplyr Backend","text":"can install released version multidplyr CRAN : development version GitHub :","code":"install.packages(\"multidplyr\") # install.packages(\"pak\") pak::pak(\"tidyverse/multidplyr\")"},{"path":"https://multidplyr.tidyverse.org/dev/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"A Multi-Process dplyr Backend","text":"use multidplyr, first create cluster desired number workers. one workers separate R process, operating system spread execution across multiple cores: two primary ways use multidplyr. first, efficient, way read different files worker: Alternatively, already data loaded main session, can use partition() automatically spread across workers. calling partition(), ’s good idea call group_by() ensure observations belonging group end worker. Now can work like regular data frame, computations spread across multiple cores. ’ve finished computation, use collect() bring data back host session: Note overhead associated copying data worker nodes back host node (vice versa), ’re best using multidplyr complex operations. See vignette(\"multidplyr\") details.","code":"library(multidplyr)  cluster <- new_cluster(4) cluster_library(cluster, \"dplyr\") #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union # Create a filename vector containing different values on each worker cluster_assign_each(cluster, filename = c(\"a.csv\", \"b.csv\", \"c.csv\", \"d.csv\"))  # Use vroom to quickly load the csvs cluster_send(cluster, my_data <- vroom::vroom(filename))  # Create a party_df using the my_data variable on each worker my_data <- party_df(cluster, \"my_data\") library(nycflights13)  flight_dest <- flights %>% group_by(dest) %>% partition(cluster) flight_dest #> Source: party_df [336,776 x 19] #> Groups: dest #> Shards: 4 [81,594--86,548 rows] #>  #> # A data frame: 336,776 × 19 #>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time #>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int> #> 1  2013     1     1      544            545        -1     1004           1022 #> 2  2013     1     1      558            600        -2      923            937 #> 3  2013     1     1      559            600        -1      854            902 #> 4  2013     1     1      602            610        -8      812            820 #> 5  2013     1     1      602            605        -3      821            805 #> 6  2013     1     1      611            600        11      945            931 #> # ℹ 336,770 more rows #> # ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>, #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, #> #   hour <dbl>, minute <dbl>, time_hour <dttm> flight_dest %>%    summarise(delay = mean(dep_delay, na.rm = TRUE), n = n()) %>%    collect() #> # A tibble: 105 × 3 #>    dest  delay     n #>    <chr> <dbl> <int> #>  1 ABQ    13.7   254 #>  2 AUS    13.0  2439 #>  3 BQN    12.4   896 #>  4 BTV    13.6  2589 #>  5 BUF    13.4  4681 #>  6 CLE    13.4  4573 #>  7 CMH    12.2  3524 #>  8 DEN    15.2  7266 #>  9 DSM    26.2   569 #> 10 DTW    11.8  9384 #> # ℹ 95 more rows"},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a function on each node of a cluster — cluster_call","title":"Call a function on each node of a cluster — cluster_call","text":"`cluster_call()` executes code worker returns results; `cluster_send()` executes code ignoring result. Jobs submitted workers parallel, wait complete.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a function on each node of a cluster — cluster_call","text":"","code":"cluster_call(cluster, code, simplify = FALSE, ptype = NULL)  cluster_send(cluster, code)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a function on each node of a cluster — cluster_call","text":"cluster cluster. code expression execute worker. simplify results simplified list?   * `TRUE`: simplify die trying.   * `NA`: simplify possible.   * `FALSE`: never try simplify, always leaving list. `code` must return vector length one order simplification   succeed. ptype `simplify` `TRUE`, use `ptype` enforce desired output type.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_call.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a function on each node of a cluster — cluster_call","text":"list results one element worker `cluster`.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_call.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a function on each node of a cluster — cluster_call","text":"","code":"cl <- default_cluster() #> Initialising default cluster of size 2  # Run code on each cluster and retrieve results cluster_call(cl, Sys.getpid()) #> [[1]] #> [1] 6359 #>  #> [[2]] #> [1] 6368 #>  cluster_call(cl, runif(1)) #> [[1]] #> [1] 0.3942487 #>  #> [[2]] #> [1] 0.5772434 #>   # use ptype to simplify cluster_call(cl, runif(1), simplify = TRUE) #> [1] 0.4326884 0.7104539  # use cluster_send() to ignore results cluster_send(cl, x <- runif(1)) cluster_call(cl, x, simplify = TRUE) #> [1] 0.6422572 0.3411853"},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster utitility functions — cluster_utils","title":"Cluster utitility functions — cluster_utils","text":"functions provide useful helpers performaning common operations. `cluster_assign()` assigns value worker; `cluster_assign_each()` assigns different values worker; `cluster_assign_partition()` partitions vectors worker gets (approximately) number pieces.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_utils.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster utitility functions — cluster_utils","text":"","code":"cluster_assign(.cluster, ...)  cluster_assign_each(.cluster, ...)  cluster_assign_partition(.cluster, ...)  cluster_copy(cluster, names, env = caller_env())  cluster_rm(cluster, names)  cluster_library(cluster, packages)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_utils.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster utitility functions — cluster_utils","text":"... Name-value pairs cluster, .cluster Cluster work names Name variables copy. env Environment look varibles copy. packages Character vector packages load","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_utils.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster utitility functions — cluster_utils","text":"Functions modify worker environment invisibly return   `cluster` calls can piped together. functions return   lists one element worker.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/cluster_utils.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster utitility functions — cluster_utils","text":"","code":"cl <- default_cluster() cluster_assign(cl, a = runif(1)) cluster_call(cl, a) #> [[1]] #> [1] 0.1803388 #>  #> [[2]] #> [1] 0.1803388 #>   # Assign different values on each cluster cluster_assign_each(cl, b = c(1, 10)) cluster_call(cl, b) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 10 #>   # Partition a vector so that each worker gets approximately the # same amount of it cluster_assign_partition(cl, c = 1:11) cluster_call(cl, c) #> [[1]] #> [1] 1 2 3 4 5 6 #>  #> [[2]] #> [1]  7  8  9 10 11 #>   # If you want different to compute different values on each # worker, use `cluster_call()` directly: cluster_call(cl, d <- runif(1)) #> [[1]] #> [1] 0.2885496 #>  #> [[2]] #> [1] 0.6946417 #>  cluster_call(cl, d) #> [[1]] #> [1] 0.2885496 #>  #> [[2]] #> [1] 0.6946417 #>   # cluster_copy() is a useful shortcut e <- 10 cluster_copy(cl, \"e\")  cluster_call(cl, ls()) #> [[1]] #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"x\" #>  #> [[2]] #> [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"x\" #>  cluster_rm(cl, letters[1:5]) cluster_call(cl, ls()) #> [[1]] #> [1] \"x\" #>  #> [[2]] #> [1] \"x\" #>   # Use cluster_library() to load packages cluster_call(cl, search()) #> [[1]] #>  [1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\"  #>  [4] \"package:grDevices\" \"package:utils\"     \"package:datasets\"  #>  [7] \"package:methods\"   \"Autoloads\"         \"tools:callr\"       #> [10] \"package:base\"      #>  #> [[2]] #>  [1] \".GlobalEnv\"        \"package:stats\"     \"package:graphics\"  #>  [4] \"package:grDevices\" \"package:utils\"     \"package:datasets\"  #>  [7] \"package:methods\"   \"Autoloads\"         \"tools:callr\"       #> [10] \"package:base\"      #>  cluster_library(cl, \"magrittr\") cluster_call(cl, search()) #> [[1]] #>  [1] \".GlobalEnv\"        \"package:magrittr\"  \"package:stats\"     #>  [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"     #>  [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"         #> [10] \"tools:callr\"       \"package:base\"      #>  #> [[2]] #>  [1] \".GlobalEnv\"        \"package:magrittr\"  \"package:stats\"     #>  [4] \"package:graphics\"  \"package:grDevices\" \"package:utils\"     #>  [7] \"package:datasets\"  \"package:methods\"   \"Autoloads\"         #> [10] \"tools:callr\"       \"package:base\"      #>"},{"path":"https://multidplyr.tidyverse.org/dev/reference/default_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Default cluster — default_cluster","title":"Default cluster — default_cluster","text":"Setting cluster relatively expensive, best use single cluster throughout session. function lazily creates 2-worker cluster use examples test.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/default_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default cluster — default_cluster","text":"","code":"default_cluster(n = 2)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/default_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default cluster — default_cluster","text":"n Number workers use; defaults 2 maximum allowed CRAN.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/default_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default cluster — default_cluster","text":"cached cluster workers.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/default_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default cluster — default_cluster","text":"","code":"default_cluster() #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/dev/reference/multidplyr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","title":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","text":"Partition data frame across multiple worker processes provide simple multicore parallelism.","code":""},{"path":[]},{"path":"https://multidplyr.tidyverse.org/dev/reference/multidplyr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"multidplyr: A Multi-Process 'dplyr' Backend — multidplyr-package","text":"Maintainer: Hadley Wickham hadley@posit.co contributors: Posit Software, PBC [copyright holder, funder]","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/new_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new cluster with sensible defaults. — new_cluster","title":"Create a new cluster with sensible defaults. — new_cluster","text":"Clusters created function automatically clean .","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/new_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new cluster with sensible defaults. — new_cluster","text":"","code":"new_cluster(n)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/new_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new cluster with sensible defaults. — new_cluster","text":"n Number workers create. Avoid setting higher number cores computer degrade performance.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/new_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new cluster with sensible defaults. — new_cluster","text":"`multidplyr_cluster` object.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/new_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new cluster with sensible defaults. — new_cluster","text":"","code":"cluster <- new_cluster(2) cluster #> 2 session cluster [..]"},{"path":"https://multidplyr.tidyverse.org/dev/reference/partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition data across workers in a cluster — partition","title":"Partition data across workers in a cluster — partition","text":"Partitioning ensures observations group end worker. try keep observations worker balanced, `partition()` uses greedy algorithm iteratively assigns group worker currently fewest rows.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition data across workers in a cluster — partition","text":"","code":"partition(data, cluster)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition data across workers in a cluster — partition","text":"data Dataset partition, typically grouped. grouped, observations group assigned cluster. cluster Cluster use.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition data across workers in a cluster — partition","text":"[party_df].","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/partition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition data across workers in a cluster — partition","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union cl <- default_cluster() cluster_library(cl, \"dplyr\")  mtcars2 <- partition(mtcars, cl) mtcars2 %>% mutate(cyl2 = 2 * cyl) #> Source: party_df [32 x 12] #> Shards: 2 [16--16 rows] #>  #> # A data frame: 32 × 12 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb  cyl2 #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4    12 #> 2  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1     8 #> 3  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2    16 #> 4  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4    16 #> 5  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2     8 #> 6  17.8     6  168.   123  3.92  3.44  18.9     1     0     4     4    12 #> # ℹ 26 more rows mtcars2 %>% filter(vs == 1) #> Source: party_df [14 x 11] #> Shards: 2 [5--9 rows] #>  #> # A data frame: 14 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  22.8     4 108      93  3.85  2.32  18.6     1     1     4     1 #> 2  22.8     4 141.     95  3.92  3.15  22.9     1     0     4     2 #> 3  17.8     6 168.    123  3.92  3.44  18.9     1     0     4     4 #> 4  30.4     4  75.7    52  4.93  1.62  18.5     1     1     4     2 #> 5  21.5     4 120.     97  3.7   2.46  20.0     1     0     3     1 #> 6  21.4     6 258     110  3.08  3.22  19.4     1     0     3     1 #> # ℹ 8 more rows mtcars2 %>% group_by(cyl) %>% summarise(n()) #> Source: party_df [6 x 2] #> Shards: 2 [3--3 rows] #>  #> # A data frame: 6 × 2 #>     cyl `n()` #>   <dbl> <int> #> 1     4     5 #> 2     6     2 #> 3     8     9 #> 4     4     6 #> 5     6     5 #> 6     8     5 mtcars2 %>% select(-cyl) #> Source: party_df [32 x 10] #> Shards: 2 [16--16 rows] #>  #> # A data frame: 32 × 10 #>     mpg  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21    160    110  3.9   2.62  16.5     0     1     4     4 #> 2  22.8  108     93  3.85  2.32  18.6     1     1     4     1 #> 3  18.7  360    175  3.15  3.44  17.0     0     0     3     2 #> 4  14.3  360    245  3.21  3.57  15.8     0     0     3     4 #> 5  22.8  141.    95  3.92  3.15  22.9     1     0     4     2 #> 6  17.8  168.   123  3.92  3.44  18.9     1     0     4     4 #> # ℹ 26 more rows"},{"path":"https://multidplyr.tidyverse.org/dev/reference/party_df.html","id":null,"dir":"Reference","previous_headings":"","what":"A `party_df` partitioned data frame — party_df","title":"A `party_df` partitioned data frame — party_df","text":"S3 class represents data frame partitioned across workers cluster. can use constructor already spread data frames spread across cluster. , start [partition()] instead.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/party_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A `party_df` partitioned data frame — party_df","text":"","code":"party_df(cluster, name, auto_rm = FALSE)"},{"path":"https://multidplyr.tidyverse.org/dev/reference/party_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A `party_df` partitioned data frame — party_df","text":"cluster cluster name Name data frame variable. Must exist every worker, data frame, names. auto_rm `TRUE`, automatically `rm()` data frame workers object created.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/party_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A `party_df` partitioned data frame — party_df","text":"S3 object class `multidplyr_party_df`.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/reference/party_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A `party_df` partitioned data frame — party_df","text":"","code":"# If a real example, you might spread file names across the clusters # and read in using data.table::fread()/vroom::vroom()/qs::qread(). cl <- default_cluster() cluster_send(cl[1], n <- 10) cluster_send(cl[2], n <- 15) cluster_send(cl, df <- data.frame(x = runif(n)))  df <- party_df(cl, \"df\") df #> Source: party_df [25 x 1] #> Shards: 2 [10--15 rows] #>  #> # A data frame: 25 × 1 #>       x #>   <dbl> #> 1 0.936 #> 2 0.420 #> 3 0.617 #> 4 0.766 #> 5 0.241 #> 6 0.769 #> # ℹ 19 more rows"},{"path":"https://multidplyr.tidyverse.org/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. magrittr %>%","code":""},{"path":[]},{"path":"https://multidplyr.tidyverse.org/dev/news/index.html","id":"multidplyr-013","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.3","title":"multidplyr 0.1.3","text":"CRAN release: 2023-03-22 Fix R CMD check failure.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/news/index.html","id":"multidplyr-012","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.2","title":"multidplyr 0.1.2","text":"CRAN release: 2022-09-26 cluster_call() gains simplify argument - use request result simplified (#136).","code":""},{"path":"https://multidplyr.tidyverse.org/dev/news/index.html","id":"multidplyr-011","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.1","title":"multidplyr 0.1.1","text":"CRAN release: 2021-12-01 Fixed problems identified part working dplyr 1.0.8.","code":""},{"path":"https://multidplyr.tidyverse.org/dev/news/index.html","id":"multidplyr-010","dir":"Changelog","previous_headings":"","what":"multidplyr 0.1.0","title":"multidplyr 0.1.0","text":"CRAN release: 2021-02-08 Added NEWS.md file track changes package.","code":""}]
